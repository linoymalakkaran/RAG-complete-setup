# Main Application Settings
app:
  name: "Company Policy & Knowledge Assistant"
  version: "1.0.0"
  environment: "development"
  debug: true

# LLM Configuration
llm:
  default_provider: "openai"
  default_model: "gpt-4-turbo-preview"
  temperature: 0.1
  max_tokens: 2000
  timeout: 30
  
  # Alternative models for comparison
  models:
    openai:
      - "gpt-4-turbo-preview"
      - "gpt-3.5-turbo"
    cohere:
      - "command-r-plus"
      - "command-r"
    local:
      - "llama-2-70b"
      - "mistral-7b"

# Embedding Configuration
embeddings:
  default_provider: "openai"
  dimension: 1536
  batch_size: 100
  
  providers:
    openai:
      model: "text-embedding-3-small"
      dimension: 1536
      max_batch_size: 2048
    
    cohere:
      model: "embed-multilingual-v3.0"
      dimension: 1024
      input_type: "search_document"
    
    local:
      model: "sentence-transformers/all-mpnet-base-v2"
      dimension: 768
      device: "cpu"  # or "cuda" for GPU
    
    multimodal:
      model: "openai/clip-vit-base-patch32"
      dimension: 512

# Document Processing
document_processing:
  # Supported file types
  supported_formats:
    - pdf
    - docx
    - txt
    - md
    - png
    - jpg
    - jpeg
    - mp4
    - avi
  
  # OCR Settings
  ocr:
    enabled: true
    engine: "tesseract"  # or "easyocr"
    languages: ["eng"]
    confidence_threshold: 0.6
  
  # Chunking Strategies
  chunking:
    default_strategy: "recursive"
    
    strategies:
      fixed:
        chunk_size: 512
        chunk_overlap: 50
        
      recursive:
        chunk_size: 1000
        chunk_overlap: 200
        separators: ["\n\n", "\n", ". ", " ", ""]
        
      semantic:
        min_chunk_size: 300
        max_chunk_size: 1500
        similarity_threshold: 0.5
        
      parent_document:
        parent_size: 2000
        child_size: 400
        child_overlap: 50
  
  # Metadata extraction
  metadata:
    extract_title: true
    extract_author: true
    extract_date: true
    extract_keywords: true

# Vector Database Configuration
vectordb:
  default: "chromadb"
  
  chromadb:
    host: "localhost"
    port: 8000
    collection_name: "company_knowledge"
    distance_metric: "cosine"  # cosine, l2, ip
    index_type: "hnsw"
    hnsw_space: "cosine"
    hnsw_construction_ef: 100
    hnsw_search_ef: 100
  
  faiss:
    index_type: "IVFFlat"  # Flat, IVFFlat, HNSW
    nlist: 100  # number of clusters
    nprobe: 10  # number of clusters to search
    
  neo4j:
    uri: "bolt://localhost:7687"
    database: "neo4j"
    entity_types: ["Person", "Department", "Policy", "Procedure"]
    relationship_types: ["REPORTS_TO", "WORKS_IN", "RELATED_TO"]

# Retrieval Configuration
retrieval:
  # Hybrid search weights
  hybrid:
    enabled: true
    dense_weight: 0.7
    sparse_weight: 0.3  # BM25
  
  # Retrieval parameters
  top_k: 5
  score_threshold: 0.7
  max_marginal_relevance: true
  mmr_lambda: 0.5  # diversity vs relevance
  
  # Reranking
  reranker:
    enabled: true
    model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    top_n: 3

# RAG Pattern Configurations
rag_patterns:
  basic:
    enabled: true
    description: "Simple retrieve and generate"
    
  self_rag:
    enabled: true
    retrieval_necessity_threshold: 0.6
    answer_quality_threshold: 0.7
    max_reflections: 2
    
  corrective_rag:
    enabled: true
    quality_threshold_high: 0.7
    quality_threshold_low: 0.3
    enable_web_search: true
    web_search_provider: "duckduckgo"  # Free web search
    max_web_results: 3
    
  agentic_rag:
    enabled: true
    max_iterations: 5
    tools: ["search", "clarify", "combine"]
    
  graph_rag:
    enabled: true
    max_depth: 3
    relationship_weight: 0.3
    
  multimodal_rag:
    enabled: true
    image_embedding_model: "clip"
    vision_model: "gpt-4-vision-preview"

# Query Enhancement
query_enhancement:
  # Multi-query generation
  multi_query:
    enabled: true
    num_variations: 3
    
  # HyDE (Hypothetical Document Embeddings)
  hyde:
    enabled: false  # Can be expensive
    
  # Query expansion
  expansion:
    enabled: true
    max_synonyms: 3

# Context Management
context:
  # Conversation memory
  memory:
    type: "buffer"  # buffer, summary, kg
    max_messages: 10
    
  # Context window
  max_context_tokens: 8000
  reserve_tokens_for_response: 1000
  
  # Lost in the middle mitigation
  context_placement: "strategic"  # first, last, strategic

# Caching Configuration
cache:
  enabled: true
  
  # Semantic cache
  semantic:
    enabled: true
    similarity_threshold: 0.95
    ttl: 3600  # seconds
    
  # Exact match cache
  exact:
    enabled: true
    ttl: 7200

# Evaluation Metrics
evaluation:
  enabled: true
  
  # Retrieval metrics
  retrieval:
    - "precision@k"
    - "recall@k"
    - "mrr"
    - "ndcg"
    - "hit_rate"
  
  # Response metrics (RAGAS)
  response:
    - "faithfulness"
    - "answer_relevance"
    - "context_relevance"
    - "answer_similarity"
  
  # Benchmarking
  benchmark:
    test_set_size: 100
    k_values: [1, 3, 5, 10]

# Guardrails
guardrails:
  # Input guardrails
  input:
    prompt_injection_detection: true
    off_topic_detection: true
    max_query_length: 500
    
  # Output guardrails
  output:
    pii_redaction: true
    hallucination_detection: true
    source_grounding_check: true
    
  # Confidence scoring
  confidence:
    enabled: true
    min_threshold: 0.5
    uncertainty_response: "I don't have enough information to answer that confidently."

# Security
security:
  api_key_required: true
  rate_limiting:
    enabled: true
    requests_per_minute: 60
    requests_per_hour: 1000
  
  authentication:
    type: "jwt"
    token_expiry: 3600

# Monitoring
monitoring:
  enabled: true
  metrics_port: 9090
  
  # What to track
  track:
    - query_latency
    - retrieval_quality
    - cache_hit_rate
    - error_rate
    - token_usage
  
  # Logging
  logging:
    level: "INFO"
    format: "json"
    file: "logs/app.log"
    rotation: "1 day"
    retention: "30 days"

# MLOps
mlops:
  mlflow:
    enabled: true
    tracking_uri: "http://localhost:5000"
    experiment_name: "rag_experiments"
    
  # What to track
  track_experiments:
    - embedding_model
    - chunk_size
    - retrieval_strategy
    - rag_pattern
    - performance_metrics

# A/B Testing
ab_testing:
  enabled: false
  variants:
    - name: "baseline"
      config: "config_v1.yaml"
      traffic_percentage: 50
    - name: "experiment"
      config: "config_v2.yaml"
      traffic_percentage: 50
