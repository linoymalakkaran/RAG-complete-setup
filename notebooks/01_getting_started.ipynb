{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0acb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY not set!\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae127b2",
   "metadata": {},
   "source": [
    "## Step 1: Document Loading\n",
    "\n",
    "First, let's load some sample documents. We support PDF, Word, text, and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.loaders.document_loaders import load_document, LoaderFactory\n",
    "\n",
    "# Create a sample document\n",
    "sample_text = \"\"\"\n",
    "COMPANY VACATION POLICY\n",
    "\n",
    "1. VACATION ENTITLEMENT\n",
    "\n",
    "All full-time employees are entitled to paid vacation time based on their length of service:\n",
    "- 0-2 years of service: 10 working days per year\n",
    "- 2-5 years of service: 15 working days per year  \n",
    "- 5+ years of service: 20 working days per year\n",
    "\n",
    "2. REQUESTING VACATION\n",
    "\n",
    "Vacation requests must be submitted through the HR portal at least 2 weeks in advance.\n",
    "Requests are subject to manager approval based on team coverage needs.\n",
    "\n",
    "3. CARRYOVER POLICY\n",
    "\n",
    "Unused vacation days may be carried over to the following year, up to a maximum of 5 days.\n",
    "Days exceeding this limit will be forfeited.\n",
    "\n",
    "4. CONTACT\n",
    "\n",
    "For questions about vacation policy, contact HR at hr@company.com or ext. 5555.\n",
    "\"\"\"\n",
    "\n",
    "# Save sample document\n",
    "sample_file = project_root / \"data\" / \"sample_documents\" / \"hr_policies\" / \"vacation_policy.txt\"\n",
    "sample_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "sample_file.write_text(sample_text)\n",
    "\n",
    "# Load the document\n",
    "doc_data = load_document(str(sample_file))\n",
    "\n",
    "print(f\"üìÑ Loaded: {doc_data['metadata']['filename']}\")\n",
    "print(f\"üìä Size: {doc_data['metadata']['file_size']} bytes\")\n",
    "print(f\"\\nüìù Content preview:\\n{doc_data['content'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53282286",
   "metadata": {},
   "source": [
    "## Step 2: Chunking Strategies\n",
    "\n",
    "Let's compare different chunking strategies to see how they split our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.chunking.chunking_strategies import chunk_document\n",
    "\n",
    "# Test different strategies\n",
    "strategies = [\n",
    "    ('fixed', {'chunk_size': 200, 'chunk_overlap': 20}),\n",
    "    ('recursive', {'chunk_size': 300, 'chunk_overlap': 50}),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for strategy, params in strategies:\n",
    "    chunks = chunk_document(\n",
    "        doc_data['content'],\n",
    "        strategy=strategy,\n",
    "        metadata={'doc_id': 'vacation_policy', 'source': 'hr'},\n",
    "        **params\n",
    "    )\n",
    "    results[strategy] = chunks\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Strategy: {strategy.upper()} ({params})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total chunks: {len(chunks)}\")\n",
    "    print(f\"Avg chunk size: {sum(len(c.content) for c in chunks) / len(chunks):.0f} chars\")\n",
    "    \n",
    "    print(f\"\\nFirst 2 chunks:\")\n",
    "    for i, chunk in enumerate(chunks[:2]):\n",
    "        print(f\"\\n--- Chunk {i+1} ({len(chunk.content)} chars) ---\")\n",
    "        print(chunk.content[:150] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c625027",
   "metadata": {},
   "source": [
    "## Step 3: Embeddings\n",
    "\n",
    "Convert text chunks into vector embeddings for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings.providers.embedding_providers import EmbeddingFactory\n",
    "\n",
    "# Create embedding provider\n",
    "# Try 'local' if you don't have OpenAI API key\n",
    "embedder = EmbeddingFactory.create(\n",
    "    provider='openai',  # or 'local' for free option\n",
    "    model='text-embedding-3-small'\n",
    ")\n",
    "\n",
    "print(f\"üìä Embedding model: {embedder.model_name}\")\n",
    "print(f\"üìè Embedding dimension: {embedder.dimension}\")\n",
    "\n",
    "# Embed a sample text\n",
    "sample_embedding = embedder.embed_text(\"What is the vacation policy?\")\n",
    "print(f\"\\n‚úÖ Embedding created: {len(sample_embedding)} dimensions\")\n",
    "print(f\"First 5 values: {sample_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed all chunks (using recursive strategy)\n",
    "chunks = results['recursive']\n",
    "chunk_texts = [chunk.content for chunk in chunks]\n",
    "\n",
    "print(f\"Embedding {len(chunk_texts)} chunks...\")\n",
    "embeddings = embedder.embed_batch(chunk_texts)\n",
    "\n",
    "print(f\"‚úÖ Embedded {len(embeddings)} chunks\")\n",
    "print(f\"Each embedding: {len(embeddings[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed63ad3",
   "metadata": {},
   "source": [
    "## Step 4: Vector Database Storage\n",
    "\n",
    "Store embeddings in ChromaDB for fast retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5492d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vectordb.chromadb_client import ChromaDBClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "vectordb = ChromaDBClient(\n",
    "    collection_name=\"rag_tutorial\",\n",
    "    persist_directory=str(project_root / \"chromadb_data\" / \"tutorial\"),\n",
    "    embedder=embedder\n",
    ")\n",
    "\n",
    "print(f\"üìä Current documents in DB: {vectordb.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad09d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add chunks to vector database\n",
    "documents = [chunk.content for chunk in chunks]\n",
    "metadatas = [chunk.metadata for chunk in chunks]\n",
    "ids = [chunk.chunk_id for chunk in chunks]\n",
    "\n",
    "vectordb.add_documents(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Added {len(documents)} documents to vector database\")\n",
    "print(f\"üìä Total documents: {vectordb.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a7c50",
   "metadata": {},
   "source": [
    "## Step 5: Test Retrieval\n",
    "\n",
    "Search for relevant chunks based on a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "query = \"How many vacation days do I get after 3 years?\"\n",
    "\n",
    "print(f\"üîç Query: {query}\\n\")\n",
    "\n",
    "# Search\n",
    "results = vectordb.search(query, top_k=3)\n",
    "\n",
    "print(f\"Found {len(results['documents'][0])} relevant chunks:\\n\")\n",
    "\n",
    "for i in range(len(results['documents'][0])):\n",
    "    doc = results['documents'][0][i]\n",
    "    distance = results['distances'][0][i]\n",
    "    similarity = 1 - distance  # Convert distance to similarity\n",
    "    \n",
    "    print(f\"--- Result {i+1} (Similarity: {similarity:.3f}) ---\")\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d27f9",
   "metadata": {},
   "source": [
    "## Step 6: Build Complete RAG Pipeline\n",
    "\n",
    "Now let's use the Basic RAG pattern to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag_patterns.basic_rag import create_basic_rag\n",
    "\n",
    "# Create RAG system\n",
    "rag = create_basic_rag(\n",
    "    vectordb=vectordb,\n",
    "    model=\"gpt-4-turbo-preview\",  # or \"gpt-3.5-turbo\" for faster/cheaper\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask questions!\n",
    "questions = [\n",
    "    \"How many vacation days do I get with 3 years of service?\",\n",
    "    \"How far in advance should I request vacation?\",\n",
    "    \"Can I carry over unused vacation days?\",\n",
    "    \"Who do I contact for vacation questions?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚ùì Q: {question}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    result = rag.query(question)\n",
    "    \n",
    "    print(f\"\\nüí° Answer:\\n{result['answer']}\")\n",
    "    \n",
    "    print(f\"\\nüìä Metadata:\")\n",
    "    print(f\"  - Tokens used: {result['metadata']['tokens_used']}\")\n",
    "    print(f\"  - Sources: {len(result['sources'])}\")\n",
    "    \n",
    "    print(f\"\\nüìö Top source (score {result['sources'][0]['score']:.3f}):\")\n",
    "    print(f\"  {result['sources'][0]['content'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30177155",
   "metadata": {},
   "source": [
    "## Step 7: Hybrid Search (Advanced)\n",
    "\n",
    "Combine dense (vector) and sparse (BM25) retrieval for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings.hybrid import create_hybrid_retriever\n",
    "\n",
    "# Create hybrid retriever\n",
    "bm25, hybrid = create_hybrid_retriever(\n",
    "    documents=documents,\n",
    "    doc_ids=ids,\n",
    "    metadata_list=metadatas,\n",
    "    dense_weight=0.7,\n",
    "    sparse_weight=0.3\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Hybrid retriever created!\")\n",
    "\n",
    "# Test hybrid search\n",
    "query = \"vacation carryover maximum\"\n",
    "\n",
    "# Get sparse results\n",
    "sparse_results = bm25.search(query, top_k=3)\n",
    "\n",
    "# Get dense results (from vector DB)\n",
    "dense_results_raw = vectordb.search(query, top_k=3)\n",
    "\n",
    "# Convert to SearchResult format\n",
    "from src.embeddings.hybrid import SearchResult\n",
    "\n",
    "dense_results = [\n",
    "    SearchResult(\n",
    "        doc_id=dense_results_raw['ids'][0][i],\n",
    "        content=dense_results_raw['documents'][0][i],\n",
    "        score=1 - dense_results_raw['distances'][0][i],\n",
    "        metadata=dense_results_raw['metadatas'][0][i],\n",
    "        source=\"dense\"\n",
    "    )\n",
    "    for i in range(len(dense_results_raw['ids'][0]))\n",
    "]\n",
    "\n",
    "# Combine\n",
    "combined_results = hybrid.combine_results(dense_results, sparse_results, top_k=3)\n",
    "\n",
    "print(f\"\\nüîç Query: {query}\")\n",
    "print(f\"\\nüìä Hybrid Results:\")\n",
    "for i, result in enumerate(combined_results, 1):\n",
    "    print(f\"\\n{i}. Score: {result.score:.3f} | Source: {result.source}\")\n",
    "    print(f\"   {result.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edfd7c",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations! üéâ You've built a complete RAG system.\n",
    "\n",
    "### Continue Learning:\n",
    "\n",
    "1. **üìì Next Notebook**: `02_chunking_strategies.ipynb` - Deep dive into chunking\n",
    "2. **üìì Embedding Comparison**: `03_embedding_comparison.ipynb` - Compare embedding models\n",
    "3. **üìì RAG Patterns**: `04_rag_patterns.ipynb` - Explore Self-RAG, CRAG, Agentic RAG\n",
    "4. **üìì Evaluation**: `05_evaluation_metrics.ipynb` - Measure and improve quality\n",
    "\n",
    "### Explore UI:\n",
    "\n",
    "```bash\n",
    "streamlit run ui/app.py\n",
    "```\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "- ‚úÖ Document loading and preprocessing\n",
    "- ‚úÖ Text chunking strategies\n",
    "- ‚úÖ Embeddings and vector representations\n",
    "- ‚úÖ Vector database storage and retrieval\n",
    "- ‚úÖ Basic RAG pipeline\n",
    "- ‚úÖ Hybrid search (dense + sparse)\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- üìñ [RAG Concepts Guide](../docs/concepts/rag_overview.md)\n",
    "- üìñ [API Documentation](../docs/api/README.md)\n",
    "- üíª [GitHub Repository](https://github.com/your-repo)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
